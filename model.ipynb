{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Reasonable & Precise Solution for ANZbank\n",
    "###### team intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First of all,We need to introduce our blueprint by 5 steps :\n",
    "Step 1 : Load data & Split features based on numerical/category\n",
    "\n",
    "Step 2 : Preprocessing for numerical & category\n",
    "\n",
    "Step 3 : Some wonderful feature engineering\n",
    "\n",
    "Step 4 : Model select with K-fold & feature importance \n",
    "\n",
    "Step 5 : Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import some usefull package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 :Load data & Split features based on numerical/category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Preprocessing for numerical & category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Some wonderful feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Model select with K-fold & feature importance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now we wanna select a perfect model to fit the data finished above, but what kind of model is right for us? According to our data:\n",
    "###### 1> its dimension is closed to normal-distribution after we do the log-op \n",
    "###### 2>this is a 2-classification Problem & Positive and negative samples are not balanced\n",
    "###### 3>a lot of Disordered-Category-Features provided with big Information-Entropy\n",
    "###### 4>no missing values & Infomation Values isn't high except \"duration\"\n",
    "###### Thus, we select the LightGBM as our model, because SVM has a low performance when it learned from these not-high-IV features & Bagging method(Random Forest) maybe bad than Boosting when solve the multi-values-features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def plot_fea_importance(classifier,X_train):\n",
    "    plt.figure(figsize=(10,12))\n",
    "    name = \"xgb\"\n",
    "    indices = np.argsort(classifier.feature_importances_)[::-1][:40]\n",
    "    g = sns.barplot(y=X_train.columns[indices][:40],\n",
    "                    x=classifier.feature_importances_[indices][:40],orient='h')\n",
    "    g.set_xlabel(\"Relative importance\", fontsize=12)\n",
    "    g.set_ylabel(\"Features\", fontsize=12)\n",
    "    g.tick_params(labelsize=9)\n",
    "    g.set_title(name + \" feature importance\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "def evaluate_cv5_lgb(train_df, test_df, cols, test=False):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_test = 0\n",
    "    oof_train = np.zeros((train_df.shape[0],))\n",
    "    for i, (train_index, val_index) in enumerate(kf.split(train_df[cols])):\n",
    "        X_train, y_train = train_df.loc[train_index, cols], train_df.y.values[train_index]\n",
    "        X_val, y_val = train_df.loc[val_index, cols], train_df.y.values[val_index]\n",
    "        lgb = LGBMClassifier(n_estimators=1000,\n",
    "                            learning_rate=0.2,\n",
    "                            num_leaves=30,\n",
    "                            colsample_bytree=.8,\n",
    "                            subsample=.9,\n",
    "                            max_depth=7,\n",
    "                            reg_alpha=.1,\n",
    "                            reg_lambda=.1,\n",
    "                            min_split_gain=.01,\n",
    "                            min_child_weight=2,\n",
    "                            silent=-1,\n",
    "                            verbose=-1,)\n",
    "        lgb.fit(X_train, y_train,\n",
    "                eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "                early_stopping_rounds=100, eval_metric=['auc'], verbose=False)\n",
    "        y_pred = lgb.predict_proba(X_val)[:,1]\n",
    "        if test:\n",
    "            y_test += lgb.predict_proba(test_df.loc[:, cols])[:,1]\n",
    "        oof_train[val_index] = y_pred\n",
    "        if i==0:\n",
    "            plot_fea_importance(lgb,X_train)\n",
    "    gc.collect()\n",
    "    auc = roc_auc_score(train_df.y.values, oof_train)\n",
    "    y_test /= 5\n",
    "    print('5 Fold auc:', auc)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_len=18000\n",
    "train,test=df[:train_len], df[train_len:]\n",
    "cols = [col for col in train.columns if col not in ['id','y','y_','duration']]\n",
    "y_pred=evaluate_cv5_lgb(train,test,cols,True)\n",
    "print(\"Test Auc:%f\"%roc_auc_score(test.y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Finally , Thanks for your reading & Best Wishes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
